---
title: Your agents are not your friends
subtitle: 'When iterating with AI, remember who’s the human.'
image: /uploads/e6deae105a07f0389c57cf7076f7957788615e59.webp
image_desc: '[Source Image: Freepik]'
publication: _publications/fast-company.md
categories:
  - _categories/journalism.md
date: 2025-10-31T04:00:00.000Z
notes: >
  [https://www.fastcompany.com/91430180/ai-agents-are-not-your-friends](https://www.fastcompany.com/91430180/ai-agents-are-not-your-friends)
---

I keep seeing articles and conferences about “humanizing” AI in one way or another. And while I get the sentiment, I think they’re taking the wrong approach. There’s no point in making technologies more human. Being human is our job. If anything, AI is less an opportunity to humanize technology, than to rehumanize ourselves. 

Let’s start at the beginning. AI is just the latest, perhaps greatest advancement yet in what OG computer scientist Norbert Wiener dubbed “cybernetic” technologies. Unlike traditional technologies, cybernetic ones take feedback from the world in order to determine their functions. They work less like a machine you turn on than a home heater’s thermostat, which turns itself off when the heat has reached a certain level. This, in turn, allows the room to cool. Then the thermostat snaps on again, using feedback from the environment to keep the room within a chosen temperature range. 

Of course, the other kind of feedback we all know about is that loud screech you get when you point a microphone too close to its speaker. The microphone is hearing its own sound, then feeding it back to the speaker, then hearing that sound, and feeding it back to the speaker again. Each feedback loop adds more sound until it screeches out of control. 

People engaging with AI prompts are vulnerable to those very same “positive” feedback loops. You come up with an idea, pose it to your favorite chat, and the more supposedly “human” the AI, the more it tries to find a way to give you positive feedback. “That sounds like a great idea for a new business, Douglas. I’m intrigued! Shall I develop a proposal with possible action points?” 

PASSIVE SPECTATORS

Round and around we go, the initial tiny utterance of a prompt getting cycled again and again, our human nervous system stimulated and reinforced by the positive feedback. Sure, we may contribute a bit to the process, but for the most part we are passive spectators of the phenomenon, marveling at how much history, logic, and speculation the AI can bring to bear. It can even create a slide presentation or video or simulated prototype of the idea suitable for presentation to others! 

Go to any business conference these days, and you’ll run into more than one entrepreneur who is high on their own supply, sharing videos of their AI’s crazy visions. Lord help the folks they convince to invest. 

As I see it, the reason they fall prey to such positive feedback loops is that they are too ready and willing to pull themselves from the equation. The AI seems so authoritative, and so human, that surely it’s aware of what it is doing. It wouldn’t be so on board with your ideas if it didn’t have some sense that it would work, right? 

YOUR AGENTS ARE NOT YOUR FRIENDS

Wrong. Don’t accept the positive reinforcement. The AI isn’t on board with the idea so much as committed to pleasing you, in the moment, like a person if it’s been trained that way. But it’s not a human, not even close, and doesn’t hold a conception of the thing you are working on. No, you, the human partner in this feedback loop, are the only one who stands a chance of conceiving or contextualizing whatever it is you’re working on. 

Your agents, like your children, are not your friends. That doesn’t mean you shouldn’t care for them. Quite the contrary, it means you have to be the one to intervene on everyone’s behalf. You are the conscious actor in the system. 

The way to prevent such positive feedback loops in our interactions with technology is to assume the role of the human. Don’t get out of the AI’s way in the name of efficiency or output. It’s cool to see all that “stuff” coming out, but if you’re not intervening in the process—actively getting in the way—you’re not going to get anywhere at all.

FOLLOW YOUR INSTINCTS

Counterintuitively, perhaps, the way to do that is to become less mechanical, less results-oriented, less utilitarian, and more feeling, more process-oriented, and even less obviously useful. Yeah, slow things down. Nurture your intuition. Lean into your own experience, expertise, and sensibilities. Reconnect with your instincts. Pause and breathe. How does that make me feel? 

For while cybernetic machines can iterate, only living beings can respirate. Instead of cycling through data, human beings can metabolize through our bodies. We can test ideas with our gut. Something doesn’t pass the smell test. A proposal feels off. This strange moment in the digital age may just be an opportunity to reclaim the uniqueness of being living, breathing, metabolizing creatures in an otherwise digital, unconscious, contextless landscape. 

Making AI’s seem more human is not doing us any favors, especially when it tempts us to relinquish our roles as the living, breathing adults in the room. 
