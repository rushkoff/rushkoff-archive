---
title: >-
  The value of the AI is not its ability to create product for us, but to engage
  with us in our process
subtitle: >-
  Too many of us are using AI as the primary architect for a project, rather
  than the general contractor who supports the architect’s human vision.
image: /uploads/50f034ec7d8973ea625645e5d743c41abc5c19f5.webp
image_desc: '[Illustration: VALERII PLOTNIKOV/Getty Images]'
publication: _publications/fast-company.md
categories:
  - _categories/journalism.md
date: 2025-10-17T04:00:00.000Z
blurb: ''
notes: >
  [https://www.fastcompany.com/91422738/ai-value-engage-our-process](https://www.fastcompany.com/91422738/ai-value-engage-our-process)
---

The most common email messages I receive these days are obviously AI-generated pitches for guests to appear on my podcast. They all begin the same way, with a praising reference to one of my recent episodes—usually the second-to-last posted show. “Your recent interview with so-and-so was penetrating, and got to the heart of the problem of x or y.” Then comes the crucial pivot: “John Dough’s work takes that problem even further . . .” And then the pitch for John Dough to be on the podcast. 

The problem is not just that the publicist used AI to shotgun the known universe of podcasters with pitches artificially customized to their shows. It’s that the comparisons and connections are really bad. “Your guest spoke so passionately about being a death doula, I think you would be so interested in an artist who makes Halloween napkins festooned with skeletons, which are usually of dead people.” 

So what do I do? I blacklist the sender. The human publicist ends up losing credibility because the one thing I might trust her to do—to accurately assess the appropriateness of my show for her guest—had been surrendered to a machine whose job was to make that connection by any means necessary. 

She was using AI in the fashion of an Industrial Age factory owner to increase her productivity, but simultaneously ignoring the human process that defines her expertise.

I see the same thing happen with AI-generated reports and presentations. Someone gets some speculative idea and then asks Chat to justify it with a few case studies. On the surface, the case studies may sound like they’re supporting the premise—but if you look any deeper, they don’t really relate at all. They’re analogous, but not truly relevant. Worse yet, they’re sitting in what looks like a fully realized Powerpoint presentation. Concepts that could have been interpreted as half-baked, speculative, or open to discussion now appear finalized. They seem inappropriately unrealized for how elaborately they have been rendered, and make the presenter seem foolish. (That is, if the recipient is even reading the work rather than having their AI summarize it.)

**DESKILLING OURSELVES**

By using the AI to do the big stuff—by outsourcing our primary competencies to the machines instead of giving them the boring busywork—we deskill ourselves and deprive everyone of the opportunity for AI-enhanced outputs. Too many of us are using AI as the primary architect for a project, rather than the general contractor who supports the architect’s human vision. (And even many of the general contractor’s functions are attributable to the human relationships they have developed over the years.) 

People are treating their chats as if they were fully realized (but as yet nonexistent) AGIs, and letting them do big stuff rather than treating them like tools that can do lots of little stuff. When facing a new seemingly gargantuan project, they turn to the AI first rather than digging in and doing some research—perhaps even using the AI as a research tool instead of relegating the whole project to it all at once. The output looks good to the user, less because it is good than because the Chat has been programmed to make the user feel good about their query. “That’s an insightful project idea, Douglas! I’ve managed to flesh out an entire proposal at three different price points.” The positive feedback loop reinforces the user behavior, until the threshold for asking the Chat to do the project is lower and lower. In the name of getting more product out there, the user loses touch with their own process—their core competency. 

**NO SHORTCUTS**

The only ones who win in such a scenario are the AI companies, who effectively commoditize the users and their companies. Without any core competencies, the only competitive advantage a user has left is the robustness of their service contract with the AI company. The fast, slapdash results are not worth the cost in human expertise. 

As the researcher behind MIT’s study “This is Your Brain on ChatGPT” explained at a recent ANDUS event, when people turn to an AI for a solution before working on a problem themselves, the number of connections formed in their brains decreases. But when they turn to the AI after working on the problem for a while, they end up with more neural connections than if they worked entirely alone. 

That’s because the value of the AI is not its ability to create product for us, but to engage with us in our process. Working and iterating with an AI—doing what we could call generative thinking—is actually a break from Industrial Age thinking. We focus less on outputs than on cycles. Less on the volume of short-term results (assembly line), and more on the quality and complexity of thought and innovation. 

AI’s don’t have to replace our competencies or even our employees. That’s less an opportunity for success and scale than it is a recipe for deskilling, commodification, and eventual disappearance. 

Adopting AI as a partner in process and enhancer of competencies requires developing a new kind of culture around technology and innovation—one that centers the human ingenuity at the core of a company, and supports the ways that new, intelligent technologies can foster that living resource. 
